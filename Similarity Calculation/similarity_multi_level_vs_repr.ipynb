{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "similarity_multi_level_vs_repr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpOWO_dFR9q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install --quiet seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4agq5rPWqcW",
        "colab_type": "code",
        "outputId": "b69e9fac-125f-44a5-cc53-40a3bd48eac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olu2hD5YSEbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import os, re, csv, logging, string\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7fTz9FvSGEA",
        "colab_type": "code",
        "outputId": "60d9c85a-7499-46be-d00f-61e3abd3d5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfQ6QkngSIv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read data from a csv file    \n",
        "def read_csv (filename, logout = True):\n",
        "\ttry:\n",
        "\t\treader = csv.reader(open(filename, \"r\"))\n",
        "\t\tdata = []\n",
        "\t\tfor r in reader:\n",
        "\t\t\tdata.append(r)\n",
        "\t\treturn data\n",
        "\texcept Exception as e:\n",
        "\t\tif logout is True:\n",
        "\t\t\tlogging.error(e)\n",
        "\t\treturn None\n",
        "  \n",
        "# write data in format of [(x1,y1,z1),(x2,y2,z2)] to a csv file\n",
        "def write_csv (filename, data, logout = True):\n",
        "\ttry:\n",
        "\t\tdoc = csv.writer (open(filename, 'w'), delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
        "\t\tfor d in data:\n",
        "\t\t\tdoc.writerow (d)\n",
        "\t\treturn True\t\t\t\n",
        "\texcept Exception as e:\n",
        "\t\tif logout is True:\n",
        "\t\t\tlog.error(e)\n",
        "\t\treturn False\n",
        "\n",
        "# remove punctuation\n",
        "def trans(s):\n",
        "  exclude = string.punctuation\n",
        "  return s.translate(str.maketrans({key: None for key in exclude}))\n",
        "\n",
        "# chunk list to approximatly equal parts\n",
        "def chunkIt(seq, num):\n",
        "    avg = len(seq) / float(num)\n",
        "    out = []\n",
        "    last = 0.0\n",
        "\n",
        "    while last < len(seq):\n",
        "        out.append(seq[int(last):int(last + avg)])\n",
        "        last += avg\n",
        "\n",
        "    return out\n",
        "\n",
        "# calculate cosine similarity in 10*10 2D array\n",
        "def tfidf_cosine_sim(model):\n",
        "    l = []\n",
        "    sim = []\n",
        "    for x in range(model.shape[0]):\n",
        "        l.append(x)\n",
        "    for m in (l[:10]):\n",
        "        for n in (l[10:]):\n",
        "            sim.append(cosine_similarity(model[m], model[n])[0][0])\n",
        "    return sim\n",
        "\n",
        "# rank cosine similarity\n",
        "def rank_question_similarities(model, corpus, corpus_i):\n",
        "    cos = []\n",
        "    for x in range(model.shape[0]):\n",
        "        sim = cosine_similarity(model[0], model[x])\n",
        "        cos.append([corpus_i[x], corpus[x], sim[0][0]])\n",
        "    return cos\n",
        "\n",
        "# calculate cosine similarity under Universal Sentence Encoder\n",
        "def get_UniSentEnc_sim(corpus, corpus_i):\n",
        "  module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
        "  embed = hub.Module(module_url)\n",
        "  init = tf.global_variables_initializer()\n",
        "  table_init = tf.tables_initializer()\n",
        "  with tf.Session() as sess:\n",
        "    sim = []\n",
        "    sess.run([init, table_init])\n",
        "    similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
        "    encoding_tensor = embed(similarity_input_placeholder)\n",
        "    for f in range(len(corpus)):\n",
        "      en_embeddings_1 = sess.run(encoding_tensor, feed_dict={similarity_input_placeholder: [corpus[0]]})\n",
        "      en_embeddings_2 = sess.run(encoding_tensor, feed_dict={similarity_input_placeholder: [corpus[f]]})\n",
        "      sim.append([corpus_i[f], corpus[f], float(cosine_similarity(en_embeddings_1, en_embeddings_2))])\n",
        "  return sim\n",
        "\n",
        "\n",
        "# calculate cosine similarity of ELmo\n",
        "def get_elmo_sim(corpus, corpus_i):\n",
        "  elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "  init = tf.global_variables_initializer()\n",
        "  table_init = tf.tables_initializer()\n",
        "  with tf.Session() as sess:\n",
        "    sim = []\n",
        "    sess.run([init, table_init])\n",
        "    similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
        "    encoding_tensor = elmo(similarity_input_placeholder)\n",
        "    for f in range(len(corpus)):\n",
        "      en_embeddings_1 = sess.run(encoding_tensor, feed_dict={similarity_input_placeholder: [corpus[0]]})\n",
        "      en_embeddings_2 = sess.run(encoding_tensor, feed_dict={similarity_input_placeholder: [corpus[f]]})\n",
        "      sim.append([corpus_i[f], corpus[f], float(cosine_similarity(en_embeddings_1, en_embeddings_2))])\n",
        "  return sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIJtRHIiB_-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yXBT-AZSSGl",
        "colab_type": "code",
        "outputId": "3d428b08-528a-4dd4-9272-69d6cbf19268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "# load data\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine_lab.csv')\n",
        "creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q1.csv')\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q2.csv')\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q3.csv')\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q4.csv')\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q5.csv')\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q6.csv')\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q7.csv')\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q8.csv')\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q9.csv')\n",
        "#creatinine_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/creatinine/creatinine_Q10.csv')\n",
        "\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c_lab.csv')\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q1.csv')\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q2.csv')\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q3.csv')\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q4.csv')\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q5.csv')\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q6.csv')\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q7.csv')\n",
        "hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q8.csv')\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q9.csv')\n",
        "#hba1c_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/hba1c/hba1c_Q10.csv')\n",
        "\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose_lab.csv')\n",
        "glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q1.csv')\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q2.csv')\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q3.csv')\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q4.csv')\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q5.csv')\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q6.csv')\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q7.csv')\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q8.csv')\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q9.csv')\n",
        "#glucose_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/glucose/glucose_Q10.csv')\n",
        "\n",
        "#noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q1.csv')\n",
        "#noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q2.csv')\n",
        "#noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q3.csv')\n",
        "noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q4.csv')\n",
        "#noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q5.csv')\n",
        "#noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q6.csv')\n",
        "#noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q7.csv')\n",
        "#noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q8.csv')\n",
        "#noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q9.csv')\n",
        "#noLab_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/noLab/noLab_Q10.csv')\n",
        "\n",
        "creatinine_id = [d[0] for d in creatinine_d]\n",
        "hba1c_id = [d[0] for d in hba1c_d]\n",
        "glucose_id = [d[0] for d in glucose_d]\n",
        "noLab_id = [d[0] for d in noLab_d]\n",
        "\n",
        "creatinine = [d[1].lower() for d in creatinine_d]\n",
        "hba1c = [d[1].lower() for d in hba1c_d]\n",
        "glucose = [d[1].lower() for d in glucose_d]\n",
        "noLab = [d[1].lower() for d in noLab_d]\n",
        "\n",
        "#creatinine_exp = [d[4] for d in creatinine_d]\n",
        "#hba1c_exp = [d[4] for d in hba1c_d]\n",
        "#glucose_exp = [d[4] for d in glucose_d]\n",
        "\n",
        "# remove punctuation\n",
        "creatinine_np = [trans(c) for c in creatinine]\n",
        "hba1c_np = [trans(c) for c in hba1c]\n",
        "glucose_np = [trans(c) for c in glucose]\n",
        "noLab_np = [trans(c) for c in noLab]\n",
        "\n",
        "# tokenization\n",
        "creatinine_token = [word_tokenize(c) for c in creatinine_np]\n",
        "hba1c_token = [word_tokenize(c) for c in hba1c_np]\n",
        "glucose_token = [word_tokenize(c) for c in glucose_np]\n",
        "noLab_token = [word_tokenize(c) for c in noLab_np]\n",
        "\n",
        "# remove stopwords\n",
        "words_stop = [str(c) for c in stopwords.words('english')]\n",
        "creatinine_no_stopw = [[cc for cc in c if cc not in words_stop]for c in creatinine_token]\n",
        "hba1c_no_stopw = [[cc for cc in c if cc not in words_stop]for c in hba1c_token]\n",
        "glucose_no_stopw = [[cc for cc in c if cc not in words_stop]for c in glucose_token]\n",
        "noLab_no_stopw = [[cc for cc in c if cc not in words_stop]for c in noLab_token]\n",
        "\n",
        "# stemming words\n",
        "ps = nltk.stem.PorterStemmer()\n",
        "creatinine_stemw = [[str(ps.stem(s)) for s in sw] for sw in creatinine_no_stopw]\n",
        "hba1c_stemw = [[str(ps.stem(s)) for s in sw] for sw in hba1c_no_stopw]\n",
        "glucose_stemw = [[str(ps.stem(s)) for s in sw] for sw in glucose_no_stopw]\n",
        "noLab_stemw = [[str(ps.stem(s)) for s in sw] for sw in noLab_no_stopw]\n",
        "\n",
        "# convert tokens back to sentence\n",
        "creatinine_stemw_s = [' '.join(i) for i in creatinine_stemw]\n",
        "hba1c_stemw_s = [' '.join(i) for i in hba1c_stemw]\n",
        "glucose_stemw_s = [' '.join(i) for i in glucose_stemw]\n",
        "noLab_stemw_s = [' '.join(i) for i in noLab_stemw]\n",
        "\n",
        "# vectorize using tfidf\n",
        "vectorizer = TfidfVectorizer(min_df=1)\n",
        "C = vectorizer.fit_transform(creatinine_stemw_s)\n",
        "H = vectorizer.fit_transform(hba1c_stemw_s)\n",
        "G = vectorizer.fit_transform(glucose_stemw_s)\n",
        "N = vectorizer.fit_transform(noLab_stemw_s)\n",
        "\n",
        "#out = rank_question_similarities(C, creatinine, creatinine_id)\n",
        "#out = rank_question_similarities(H, hba1c, hba1c_id)\n",
        "#out = rank_question_similarities(G,glucose, glucose_id)\n",
        "#out = rank_question_similarities(N,noLab, noLab_id)\n",
        "#write_csv('/content/drive/My Drive/Thesis_feature_sim/test.csv', out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUNsATRVcHok",
        "colab_type": "code",
        "outputId": "d6d4ffcd-6ce0-4c78-e272-fd3e7c5691e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Universal Sentence Encoder: calculate cosine similarity\n",
        "#sim = get_UniSentEnc_sim(creatinine, creatinine_id)\n",
        "#sim = get_UniSentEnc_sim(hba1c, hba1c_id)\n",
        "#sim = get_UniSentEnc_sim(glucose, glucose_id)\n",
        "#sim = get_UniSentEnc_sim(noLab, noLab_id)\n",
        "\n",
        "# ELMo: caculate cosine similarity\n",
        "#sim = get_elmo_sim(creatinine, creatinine_id)\n",
        "sim = get_elmo_sim(hba1c, hba1c_id)\n",
        "#sim = get_elmo_sim(glucose, glucose_id)\n",
        "#sim = get_elmo_sim(noLab, noLab_id)\n",
        "\n",
        "write_csv('/content/drive/My Drive/Thesis_feature_sim/test.csv', sim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut5a2fwySgSq",
        "colab_type": "code",
        "outputId": "b18e80e2-ac7a-4d57-a692-df2e614877cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load mixed data\n",
        "#hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q1.csv')\n",
        "#hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q2.csv')\n",
        "hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q3.csv')\n",
        "#hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q4.csv')\n",
        "#hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q5.csv')\n",
        "#hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q6.csv')\n",
        "#hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q7.csv')\n",
        "#hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q8.csv')\n",
        "#hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q9.csv')\n",
        "#hba1c_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/HbA1c_top10mix_Q10.csv')\n",
        "\n",
        "#noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q1.csv')\n",
        "#noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q2.csv')\n",
        "noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q3.csv')\n",
        "#noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q4.csv')\n",
        "#noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q5.csv')\n",
        "#noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q6.csv')\n",
        "#noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q7.csv')\n",
        "#noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q8.csv')\n",
        "#noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q9.csv')\n",
        "#noLab_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/NoLab_top10mix_Q10.csv')\n",
        "\n",
        "#glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q1.csv')\n",
        "#glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q2.csv')\n",
        "#glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q3.csv')\n",
        "#glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q4.csv')\n",
        "glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q5.csv')\n",
        "#glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q6.csv')\n",
        "#glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q7.csv')\n",
        "#glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q8.csv')\n",
        "#glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q9.csv')\n",
        "#glucose_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Glucose_top10mix_Q10.csv')\n",
        "\n",
        "#creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q1.csv')\n",
        "creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q2.csv')\n",
        "#creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q3.csv')\n",
        "#creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q4.csv')\n",
        "#creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q5.csv')\n",
        "#creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q6.csv')\n",
        "#creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q7.csv')\n",
        "#creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q8.csv')\n",
        "#creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q9.csv')\n",
        "#creatinine_mix_d = read_csv('/content/drive/My Drive/Thesis_feature_sim/mix_csv/Creatinine_top10mix_Q10.csv')\n",
        "\n",
        "# extract id\n",
        "hba1c_mix_id = [d[0] for d in hba1c_mix_d]\n",
        "noLab_mix_id = [d[0] for d in noLab_mix_d]\n",
        "glucose_mix_id = [d[0] for d in glucose_mix_d]\n",
        "creatinine_mix_id = [d[0] for d in creatinine_mix_d]\n",
        "\n",
        "# extract question and convert to lowercase\n",
        "hba1c_mix = [d[1].lower() for d in hba1c_mix_d]\n",
        "noLab_mix = [d[1].lower() for d in noLab_mix_d]\n",
        "glucose_mix = [d[1].lower() for d in glucose_mix_d]\n",
        "creatinine_mix = [d[1].lower() for d in creatinine_mix_d]\n",
        "\n",
        "# remove punctuation\n",
        "hba1c_mix_np = [trans(c) for c in hba1c_mix]\n",
        "noLab_mix_np = [trans(c) for c in noLab_mix]\n",
        "glucose_mix_np = [trans(c) for c in glucose_mix]\n",
        "creatinine_mix_np = [trans(c) for c in creatinine_mix]\n",
        "\n",
        "# tokenization\n",
        "hba1c_mix_token = [word_tokenize(c) for c in hba1c_mix_np]\n",
        "noLab_mix_token = [word_tokenize(c) for c in noLab_mix_np]\n",
        "glucose_mix_token = [word_tokenize(c) for c in glucose_mix_np]\n",
        "creatinine_mix_token = [word_tokenize(c) for c in creatinine_mix_np]\n",
        "\n",
        "# remove stopwords\n",
        "words_stop = [str(c) for c in stopwords.words('english')]\n",
        "hba1c_mix_no_stopw = [[cc for cc in c if cc not in words_stop]for c in hba1c_mix_token]\n",
        "noLab_mix_no_stopw = [[cc for cc in c if cc not in words_stop]for c in noLab_mix_token]\n",
        "glucose_mix_no_stopw = [[cc for cc in c if cc not in words_stop]for c in glucose_mix_token]\n",
        "creatinine_mix_no_stopw = [[cc for cc in c if cc not in words_stop]for c in creatinine_mix_token]\n",
        "\n",
        "# stemming words\n",
        "ps = nltk.stem.PorterStemmer()\n",
        "hba1c_mix_stemw = [[str(ps.stem(s)) for s in sw] for sw in hba1c_mix_no_stopw]\n",
        "noLab_mix_stemw = [[str(ps.stem(s)) for s in sw] for sw in noLab_mix_no_stopw]\n",
        "glucose_mix_stemw = [[str(ps.stem(s)) for s in sw] for sw in glucose_mix_no_stopw]\n",
        "creatinine_mix_stemw = [[str(ps.stem(s)) for s in sw] for sw in creatinine_mix_no_stopw]\n",
        "\n",
        "# convert tokens back to sentence\n",
        "hba1c_mix_stemw_s = [' '.join(i) for i in hba1c_mix_stemw]\n",
        "noLab_mix_stemw_s = [' '.join(i) for i in noLab_mix_stemw]\n",
        "glucose_mix_stemw_s = [' '.join(i) for i in glucose_mix_stemw]\n",
        "creatinine_mix_stemw_s = [' '.join(i) for i in creatinine_mix_stemw]\n",
        "\n",
        "# vectorize using tfidf\n",
        "vectorizer = TfidfVectorizer(min_df=1)\n",
        "Hm = vectorizer.fit_transform(hba1c_mix_stemw_s)\n",
        "Nm = vectorizer.fit_transform(noLab_mix_stemw_s)\n",
        "Gm = vectorizer.fit_transform(glucose_mix_stemw_s)\n",
        "Cm = vectorizer.fit_transform(creatinine_mix_stemw_s)\n",
        "\n",
        "#out = rank_question_similarities(Hm, hba1c_mix, hba1c_mix_id)\n",
        "#out = rank_question_similarities(Nm,noLab_mix, noLab_mix_id)\n",
        "out = rank_question_similarities(Gm,glucose_mix, glucose_mix_id)\n",
        "#out = rank_question_similarities(Cm,creatinine_mix, creatinine_mix_id)\n",
        "write_csv('/content/drive/My Drive/Thesis_feature_sim/test.csv', out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI8C51ktTehr",
        "colab_type": "code",
        "outputId": "822082a1-8098-4fd3-ebfe-d80d116e9215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Universal Sentence Encoder: calculate cosine similarity\n",
        "#sim = get_UniSentEnc_sim(hba1c_mix, hba1c_mix_id)\n",
        "#sim = get_UniSentEnc_sim(noLab_mix, noLab_mix_id)\n",
        "#sim = get_UniSentEnc_sim(glucose_mix, glucose_mix_id)\n",
        "#sim = get_UniSentEnc_sim(creatinine_mix, creatinine_mix_id)\n",
        "\n",
        "# ELMo: caculate cosine similarity\n",
        "sim = get_elmo_sim(hba1c_mix, hba1c_mix_id)\n",
        "#sim = get_elmo_sim(noLab_mix, noLab_mix_id)\n",
        "#sim = get_elmo_sim(glucose_mix, glucose_mix_id)\n",
        "#sim = get_elmo_sim(creatinine_mix, creatinine_mix_id)\n",
        "\n",
        "write_csv('/content/drive/My Drive/Thesis_feature_sim/test.csv', sim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}